Another experiment in Streamlit, this time utilizing Ollama. 
Don't take this very seriously, it's just for fun (and practice). 
I am trying to build towards a stock portfolio using Streamlit, so 
this is mostly just to play around with streamlit and too see if I can 
get it to work. 

And also partly because the buzz-word bonanaza at LinkedIn is quite annoying. 

I really relied heavyily on chatgpt here, but I learned a bit and had a bunch of fun. 


How to run

```bash

streamlit run main.py
```

How to install 

create a venv 

```bash

python -m venv .venv
```

install requirements

```bash

pip -r install requirements.txt

```

TODO - video to text functionality 

 - find a library of fluffy videos 
 - extract frames, maybe 1 fr a second
 - feed image to im to text model 
 - 

